services:
  # Console - unified web interface for fleet operations
  # Replaces both portal and operator
  console:
    build:
      context: ./console
      dockerfile: Dockerfile
    container_name: depot-console
    restart: unless-stopped
    ports:
      - "80:80"
    environment:
      # Authentication: set password to enable, leave empty to disable
      # When accessed via Tailscale Serve/Funnel, Tailscale identity is used instead
      - CONSOLE_PASSWORD=${CONSOLE_PASSWORD:-}
      - CONSOLE_USERNAME=${CONSOLE_USERNAME:-admin}
    depends_on:
      - grafana
      - influxdb
      - discovery
    healthcheck:
      test: ["CMD", "wget", "-q", "-O-", "http://localhost/health"]
      interval: 10s
      timeout: 3s
      retries: 3

  # Rover discovery service - rovers register here, operators query here
  discovery:
    build:
      context: ./discovery
      dockerfile: Dockerfile
    container_name: depot-discovery
    restart: unless-stopped
    ports:
      - "4860:4860"
    environment:
      - PORT=4860
      - RUST_LOG=discovery=info
    healthcheck:
      test: ["CMD", "wget", "-q", "-O-", "http://localhost:4860/health"]
      interval: 10s
      timeout: 3s
      retries: 3

  # InfluxDB for real-time metrics from rovers
  influxdb:
    image: influxdb:2.7
    container_name: depot-influxdb
    restart: unless-stopped
    ports:
      - "8086:8086" # HTTP API + UI
      - "8089:8089/udp" # UDP line protocol input
    volumes:
      - influxdb-data:/var/lib/influxdb2
      - influxdb-config:/etc/influxdb2
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=${INFLUXDB_ADMIN_USER:-admin}
      - DOCKER_INFLUXDB_INIT_PASSWORD=${INFLUXDB_ADMIN_PASSWORD:-munipassword}
      - DOCKER_INFLUXDB_INIT_ORG=${INFLUXDB_ORG:-muni}
      - DOCKER_INFLUXDB_INIT_BUCKET=${INFLUXDB_BUCKET:-muni}
      - DOCKER_INFLUXDB_INIT_ADMIN_TOKEN=${INFLUXDB_ADMIN_TOKEN:-muni-dev-token}
    healthcheck:
      test: ["CMD", "influx", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Grafana for fleet dashboards
  grafana:
    image: grafana/grafana:11.4.0
    container_name: depot-grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
      - ./grafana/dashboards:/var/lib/grafana/dashboards:ro
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-munipassword}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_AUTH_ANONYMOUS_ENABLED=false
      # Serve from /grafana/ subpath behind console proxy
      - GF_SERVER_ROOT_URL=%(protocol)s://%(domain)s/grafana/
      - GF_SERVER_SERVE_FROM_SUB_PATH=true
      # InfluxDB connection for provisioning
      - INFLUXDB_URL=http://influxdb:8086
      - INFLUXDB_ORG=${INFLUXDB_ORG:-muni}
      - INFLUXDB_TOKEN=${INFLUXDB_ADMIN_TOKEN:-muni-dev-token}
    depends_on:
      influxdb:
        condition: service_healthy

  # SFTP server for session file uploads from rovers
  sftp:
    image: atmoz/sftp:alpine
    container_name: depot-sftp
    restart: unless-stopped
    ports:
      - "2222:22"
    volumes:
      # Session storage (rovers upload here)
      - sessions-data:/home/bvr/sessions
      # SSH host keys (pre-generated, required for sshd)
      - ./sftp/ssh_host_keys/ssh_host_ed25519_key:/etc/ssh/ssh_host_ed25519_key:ro
      - ./sftp/ssh_host_keys/ssh_host_rsa_key:/etc/ssh/ssh_host_rsa_key:ro
    # Format: user:password:uid:gid:directories
    # For production: use key-based auth by mounting authorized_keys
    command: "bvr:${SFTP_PASSWORD:-dev}:1000:1000:sessions"

  # Map processing service - watches sessions, builds maps
  mapper:
    build:
      context: ./mapper
      dockerfile: Dockerfile
    container_name: depot-mapper
    restart: unless-stopped
    volumes:
      - sessions-data:/data/sessions:ro
      - maps-data:/data/maps
      - jobs-data:/data/jobs
    environment:
      - SESSIONS_DIR=/data/sessions
      - MAPS_DIR=/data/maps
      - JOBS_DIR=/data/jobs
      - RUST_LOG=mapper=info
    depends_on:
      sftp:
        condition: service_started

  # Gaussian splatting worker - processes sessions into 3D splats
  # Requires NVIDIA GPU runtime: docker compose --profile gpu up
  splat-worker:
    build:
      context: ./splat-worker
      dockerfile: Dockerfile
    container_name: depot-splat-worker
    restart: unless-stopped
    profiles:
      - gpu
    volumes:
      - sessions-data:/data/sessions:ro
      - maps-data:/data/maps
      - jobs-data:/data/jobs
    environment:
      - SESSIONS_DIR=/data/sessions
      - MAPS_DIR=/data/maps
      - JOBS_DIR=/data/jobs
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    depends_on:
      - mapper

  # GPS status service - reads ZED-F9P status for base station monitoring
  gps-status:
    build:
      context: ./gps-status
      dockerfile: Dockerfile
    container_name: depot-gps-status
    restart: unless-stopped
    ports:
      - "4880:4880"
    devices:
      - /dev/ttyACM0:/dev/ttyACM0
    environment:
      - PORT=4880
      - GPS_SERIAL_PORT=/dev/ttyACM0
      - GPS_BAUD_RATE=115200
      - RUST_LOG=gps_status=info
    # Only start if base station hardware is connected
    profiles:
      - rtk
    healthcheck:
      test: ["CMD", "wget", "-q", "-O-", "http://localhost:4880/health"]
      interval: 10s
      timeout: 3s
      retries: 3

  # NTRIP caster for RTK corrections
  # Base station ZED-F9P connects via USB, broadcasts RTCM3 to rovers
  ntrip:
    image: ghcr.io/rtklibexplorer/str2str:latest
    container_name: depot-ntrip
    restart: unless-stopped
    ports:
      - "2101:2101"
    devices:
      - /dev/ttyUSB0:/dev/ttyUSB0
    command: >
      -in serial://ttyUSB0:115200:8:n:1
      -out ntrips://:${NTRIP_PASSWORD:-muni}@:2101/ROVER
    environment:
      - NTRIP_PASSWORD=${NTRIP_PASSWORD:-muni}
    # Only start if base station hardware is connected
    profiles:
      - rtk

  # Map API service - serves maps to console app
  map-api:
    build:
      context: ./map-api
      dockerfile: Dockerfile
    container_name: depot-map-api
    restart: unless-stopped
    ports:
      - "4870:4870"
    volumes:
      - maps-data:/data/maps:ro
    environment:
      - MAPS_DIR=/data/maps
      - PORT=4870
      - RUST_LOG=map_api=info
    healthcheck:
      test: ["CMD", "wget", "-q", "-O-", "http://localhost:4870/health"]
      interval: 10s
      timeout: 3s
      retries: 3

volumes:
  influxdb-data:
  influxdb-config:
  grafana-data:
  sessions-data:
  maps-data:
  jobs-data:
